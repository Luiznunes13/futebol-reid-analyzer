{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_DoKJnjM-Rg"
      },
      "source": [
        "# üßë‚Äçüè´ Aula 3 - RP com Vis√£o: Avalia√ß√£o do Modelo e Defini√ß√£o de Limiares\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Sum√°rio\n",
        "\n",
        "1. [Introdu√ß√£o](#1-introdu√ß√£o)\n",
        "2. [M√©tricas de Avalia√ß√£o do Azure](#2-m√©tricas-de-avalia√ß√£o-do-azure)\n",
        "3. [Teste com Novas Imagens (Conjunto de Teste)](#3-teste-com-novas-imagens-conjunto-de-teste)\n",
        "4. [An√°lise de Limiares (Threshold)](#4-an√°lise-de-limiares-threshold)\n",
        "5. [Publica√ß√£o e Consumo do Modelo](#5-publica√ß√£o-e-consumo-do-modelo)\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Capacidades T√©cnicas Trabalhadas\n",
        "\n",
        "- **Utilizar m√©todo de classifica√ß√£o supervisionada** para reconhecimento de padr√µes.\n",
        "- **Selecionar o m√©todo mais adequado** para o reconhecimento de padr√µes.\n",
        "\n",
        "## ü§ù Capacidades Socioemocionais Trabalhadas\n",
        "\n",
        "- **√âtica**: Apresentar comportamento √©tico na conduta profissional.\n",
        "- **Resolu√ß√£o de problemas complexos**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfxOMQEKM-Rj"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Introdu√ß√£o\n",
        "\n",
        "Na aula anterior, treinamos o modelo. Agora precisamos saber: **ele √© bom o suficiente?**\n",
        "\n",
        "Vamos analisar:\n",
        "- **Precision (Precis√£o)**: Quando o modelo diz que √© \"Defeito X\", ele acerta?\n",
        "- **Recall (Revoca√ß√£o)**: De todos os \"Defeitos X\" que existem, quantos o modelo encontrou?\n",
        "- **Matriz de Confus√£o**: Onde o modelo est√° errando?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QylzdL0P05Q",
        "outputId": "a696b889-c5b1-4815-c15c-2d26c8ff5cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLaFPorYM-Rk",
        "outputId": "b1b90626-a59e-42b9-8f02-1f3db9a59019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure-cognitiveservices-vision-customvision\n",
            "  Downloading azure_cognitiveservices_vision_customvision-3.1.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting msrest>=0.6.21 (from azure-cognitiveservices-vision-customvision)\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting azure-common~=1.1 (from azure-cognitiveservices-vision-customvision)\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.2.0 (from azure-cognitiveservices-vision-customvision)\n",
            "  Downloading azure_mgmt_core-1.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting azure-core>=1.32.0 (from azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision)\n",
            "  Downloading azure_core-1.38.2-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2026.1.4)\n",
            "Collecting isodate>=0.6.0 (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.0.0)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.12/dist-packages (from msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from azure-core>=1.32.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-cognitiveservices-vision-customvision) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.16->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (2.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-cognitiveservices-vision-customvision) (3.3.1)\n",
            "Downloading azure_cognitiveservices_vision_customvision-3.1.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading azure_mgmt_core-1.6.0-py3-none-any.whl (29 kB)\n",
            "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.38.2-py3-none-any.whl (217 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m218.0/218.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: azure-common, isodate, azure-core, msrest, azure-mgmt-core, azure-cognitiveservices-vision-customvision\n",
            "Successfully installed azure-cognitiveservices-vision-customvision-3.1.1 azure-common-1.1.28 azure-core-1.38.2 azure-mgmt-core-1.6.0 isodate-0.7.2 msrest-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install azure-cognitiveservices-vision-customvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGy6yLagM-Rl",
        "outputId": "d73d6164-3b03-46cb-ddf8-59a4b29d42be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ SDK do Azure carregada.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Bibliotecas do Azure (necess√°rio ter instalado na Aula 2)\n",
        "try:\n",
        "    from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
        "    from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "    from msrest.authentication import ApiKeyCredentials\n",
        "    print(\"‚úÖ SDK do Azure carregada.\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è SDK do Azure n√£o instalada. Execute: pip install azure-cognitiveservices-vision-customvision\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FQyPq0PM-Rm"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. M√©tricas de Avalia√ß√£o do Azure\n",
        "\n",
        "O pr√≥prio Azure fornece m√©tricas da itera√ß√£o treinada. Podemos acess√°-las via c√≥digo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byhrZn3jM-Rn",
        "outputId": "672ea7de-1afe-4a17-d4ab-61ae082c3609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Performance da Itera√ß√£o: Iteration 1\n",
            "   Precision: 100.00%\n",
            "   Recall:    57.85%\n",
            "   mAP:       96.13%\n",
            "\n",
            "üìå Por Classe:\n",
            "   - bed_no_stick: P=1.00, R=0.40\n",
            "   - leg_broken: P=1.00, R=0.48\n",
            "   - no_bottom: P=0.00, R=0.00\n",
            "   - no_defected: P=1.00, R=0.60\n",
            "   - no_support: P=1.00, R=0.73\n"
          ]
        }
      ],
      "source": [
        "# Configura√ß√µes\n",
        "ENDPOINT = \"https://custom3dprinterbrandao.cognitiveservices.azure.com/\"\n",
        "ENDPOINT_PREDICTION = \"https://custom3dprinterbrandao-Prediction.cognitiveservices.azure.com/\"\n",
        "TRAINING_KEY = \"<REDACTED_TRAINING_KEY>\"\n",
        "PREDICTION_KEY = \"<REDACTED_PREDICTION_KEY>\" # Necess√°ria para teste\n",
        "PREDICTION_RESOURCE_ID = \"custom3dprinterbrandao-Prediction\"\n",
        "PROJECT_ID = \"33ee74bf-84e1-4d52-ba35-798ba4a41fc8\" # ID do projeto criado na aula 2\n",
        "\n",
        "def get_metrics(trainer, project_id):\n",
        "    if trainer is None: return\n",
        "\n",
        "    # Pega a √∫ltima itera√ß√£o\n",
        "    iterations = trainer.get_iterations(project_id)\n",
        "    latest_iteration = iterations[0]\n",
        "\n",
        "    # Pega performance\n",
        "    performance = trainer.get_iteration_performance(project_id, latest_iteration.id)\n",
        "\n",
        "    print(f\"üìä Performance da Itera√ß√£o: {latest_iteration.name}\")\n",
        "    print(f\"   Precision: {performance.precision:.2%}\")\n",
        "    print(f\"   Recall:    {performance.recall:.2%}\")\n",
        "    print(f\"   mAP:       {performance.average_precision:.2%}\")\n",
        "\n",
        "    # Performance por Tag\n",
        "    print(\"\\nüìå Por Classe:\")\n",
        "    for tag_perf in performance.per_tag_performance:\n",
        "        print(f\"   - {tag_perf.name}: P={tag_perf.precision:.2f}, R={tag_perf.recall:.2f}\")\n",
        "\n",
        "# Exemplo de uso:\n",
        "credentials = ApiKeyCredentials(in_headers={\"Training-key\": TRAINING_KEY})\n",
        "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
        "get_metrics(trainer, PROJECT_ID)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = trainer.get_iterations(PROJECT_ID)\n",
        "latest_iteration = iterations[0]\n",
        "\n",
        "ITERATION_ID = latest_iteration.id\n",
        "PUBLISH_ITERATION_NAME = latest_iteration.name\n",
        "\n",
        "print(ITERATION_ID)\n",
        "\n",
        "print(f\"Publishing the current iteration as '{PUBLISH_ITERATION_NAME}'...\")\n",
        "trainer.publish_iteration(\n",
        "    PROJECT_ID,\n",
        "    ITERATION_ID,\n",
        "    PUBLISH_ITERATION_NAME,\n",
        "    PREDICTION_RESOURCE_ID\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "6hRzcDzjUYdz",
        "outputId": "1dd681d3-071c-4b0a-809f-0cda6d6b720a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03d5d68a-9acb-4330-b705-1abb334be35d\n",
            "Publishing the current iteration as 'Iteration 1'...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CustomVisionErrorException",
          "evalue": "Iteration is already published as: Iteration1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCustomVisionErrorException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1254255436.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Publishing the current iteration as '{PUBLISH_ITERATION_NAME}'...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m trainer.publish_iteration(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mITERATION_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/azure/cognitiveservices/vision/customvision/training/operations/_custom_vision_training_client_operations.py\u001b[0m in \u001b[0;36mpublish_iteration\u001b[0;34m(self, project_id, iteration_id, publish_name, prediction_id, overwrite, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomVisionErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCustomVisionErrorException\u001b[0m: Iteration is already published as: Iteration1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oKSbP9HM-Ro"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Teste com Novas Imagens (Conjunto de Teste)\n",
        "\n",
        "Vamos usar o Custom Vision **Prediction Client** para enviar as imagens que separamos na pasta `processed_data/vision/test` e ver o resultado real."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "hL4Yqe1sM-Ro",
        "outputId": "047ea7f3-c728-4b9e-8eab-41b40d4f8589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "03d5d68a-9acb-4330-b705-1abb334be35d\n",
            "Publishing the current iteration as 'Iteration1'...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CustomVisionErrorException",
          "evalue": "Invalid prediction resource id",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCustomVisionErrorException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-290417538.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomVisionPredictionClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mENDPOINT_PREDICTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_credentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mTEST_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/VisaÃÉo Computacional/Azure - Custom Vision/3D-Printer-AvaliacÃßaÃÉo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-290417538.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(prediction_client, project_id, test_dir, threshold)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Publishing the current iteration as '{PUBLISH_ITERATION_NAME}'...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     trainer.publish_iteration(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mITERATION_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/azure/cognitiveservices/vision/customvision/training/operations/_custom_vision_training_client_operations.py\u001b[0m in \u001b[0;36mpublish_iteration\u001b[0;34m(self, project_id, iteration_id, publish_name, prediction_id, overwrite, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCustomVisionErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCustomVisionErrorException\u001b[0m: Invalid prediction resource id"
          ]
        }
      ],
      "source": [
        "# Publicar itera√ß√£o antes de testar (se ainda n√£o estiver)\n",
        "import time\n",
        "\n",
        "def test_model(prediction_client, project_id, test_dir, threshold=0.5):\n",
        "    if prediction_client is None: return\n",
        "\n",
        "    # O nome da publica√ß√£o costuma ser \"Iteration1\" ou similar\n",
        "    PUBLISH_NAME = \"Iteration1\"\n",
        "\n",
        "    print(f\"Testando imagens de {test_dir}...\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for folder in test_dir.iterdir():\n",
        "        if folder.is_dir():\n",
        "            true_label = folder.name\n",
        "            images = list(folder.glob(\"*.jpg\"))[:5] # Testar 5 de cada para economizar tempo/quota\n",
        "\n",
        "            for img_path in images:\n",
        "                with open(img_path, \"rb\") as image_contents:\n",
        "                    prediction = prediction_client.classify_image(\n",
        "                        project_id,\n",
        "                        PUBLISH_NAME,\n",
        "                        image_contents.read()\n",
        "                    )\n",
        "\n",
        "                # Pega a melhor predi√ß√£o\n",
        "                best_pred = prediction.predictions[0]\n",
        "\n",
        "                # Aplica filtro de threshold\n",
        "                pred_label = best_pred.tag_name if best_pred.probability >= threshold else \"Uncertain\"\n",
        "\n",
        "                results.append({\n",
        "                    \"image\": img_path.name,\n",
        "                    \"true\": true_label,\n",
        "                    \"pred\": pred_label,\n",
        "                    \"prob\": best_pred.probability\n",
        "                })\n",
        "                print(f\"Img: {img_path.name} | Real: {true_label} -> Pred: {pred_label} ({best_pred.probability:.2%})\")\n",
        "                import time\n",
        "                time.sleep(1)\n",
        "    return results\n",
        "\n",
        "# Exemplo de uso:\n",
        "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
        "predictor = CustomVisionPredictionClient(ENDPOINT_PREDICTION, prediction_credentials)\n",
        "TEST_DIR = Path(\"/content/drive/MyDrive/Colab Notebooks/VisaÃÉo Computacional/Azure - Custom Vision/3D-Printer-AvaliacÃßaÃÉo\")\n",
        "results = test_model(predictor, PROJECT_ID, TEST_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBiMfawIM-Rp"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. An√°lise de Limiares (Threshold)\n",
        "\n",
        "O modelo retorna uma probabilidade (0 a 1). Precisamos decidir a partir de quanto confiamos na resposta.\n",
        "\n",
        "- **Threshold Alto (>0.8)**: Menos falsos positivos, mas podemos perder defeitos reais (Falso Negativo).\n",
        "- **Threshold Baixo (<0.5)**: Detectamos tudo, mas muito alarme falso.\n",
        "\n",
        "### Exemplo Pr√°tico\n",
        "Se o modelo diz \"leg_broken\" com 40% de certeza, devemos parar a impressora?\n",
        "\n",
        "> **Discuss√£o:** Em manufatura, errar um defeito (deixar passar) √© pior do que um falso alarme? Ou parar a linha toda hora por falso alarme √© invi√°vel?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbQDDviSM-Rp",
        "outputId": "d48f0bdf-114f-4cb1-a360-68d69fbb0b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilidades de defeito encontradas: [0.95, 0.82, 0.6, 0.45, 0.1]\n",
            "Threshold 0.5: 3 detectados\n",
            "Threshold 0.7: 2 detectados\n",
            "Threshold 0.9: 1 detectados\n"
          ]
        }
      ],
      "source": [
        "# Simula√ß√£o de impacto de threshold\n",
        "probs = [0.95, 0.82, 0.60, 0.45, 0.10]\n",
        "print(\"Probabilidades de defeito encontradas:\", probs)\n",
        "\n",
        "for t in [0.5, 0.7, 0.9]:\n",
        "    detected = [p for p in probs if p >= t]\n",
        "    print(f\"Threshold {t}: {len(detected)} detectados\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoGz7jy5M-Rq"
      },
      "source": [
        "---\n",
        "\n",
        "## 5. Publica√ß√£o e Consumo do Modelo\n",
        "\n",
        "Para integrar com o Sistema Baseado em Conhecimento (SBC), o modelo precisa expor uma API.\n",
        "No Azure, isso √© feito clicando em **Publish**.\n",
        "\n",
        "A sa√≠da para o SBC √© um pacote de \"Fatos\":\n",
        "```json\n",
        "{\n",
        "  \"source\": \"vision_module\",\n",
        "  \"detected_class\": \"leg_broken\",\n",
        "  \"confidence\": 0.92,\n",
        "  \"timestamp\": \"2024-02-14T10:00:00\"\n",
        "}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}